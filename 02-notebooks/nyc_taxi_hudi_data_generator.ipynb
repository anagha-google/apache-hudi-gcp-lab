{"cells":[{"cell_type":"markdown","id":"9263faa9","metadata":{},"source":["# Generate NYC taxi trip data in Hudi format"]},{"cell_type":"markdown","id":"4beb7e92","metadata":{},"source":["This notebook reads NYC taxi trips (yellow and green) off of a Parquet dataset in Cloud Storage and persists as Hudi to Cloud Storage. It takes about 30 minutes to complete."]},{"cell_type":"markdown","id":"336857af","metadata":{},"source":["### 1. Get or create Spark Session with requisite Hudi configs"]},{"cell_type":"code","execution_count":1,"id":"ce15aea1","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/28 23:22:25 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = SparkSession.builder \\\n","  .appName(\"NYC Taxi Hudi Data Generator\") \\\n","  .master(\"yarn\")\\\n","  .enableHiveSupport()\\\n","  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n","  .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n","  .getOrCreate()"]},{"cell_type":"markdown","id":"be428574","metadata":{},"source":["### 2. Variables"]},{"cell_type":"code","execution_count":2,"id":"ad55111b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Project ID:  apache-hudi-lab\n","Project Number:  623600433888\n","PERSIST_TO_BUCKET:  gs://gaia_data_bucket-623600433888\n"]}],"source":["import os\n","\n","PROJECT_ID = \"\"\n","PROJECT_NBR = \"\"\n","\n","# Get your Google Cloud project ID from gcloud\n","if not os.getenv(\"IS_TESTING\"):\n","    project_id_output = !gcloud config list --format 'value(core.project)' 2>/dev/null\n","    PROJECT_ID = project_id_output[0]\n","    print(\"Project ID: \", PROJECT_ID)\n","    \n","    \n","    project_nbr_output = !gcloud projects describe $PROJECT_ID --format='value(projectNumber)'\n","    PROJECT_NBR = project_nbr_output[0]\n","    print(\"Project Number: \", PROJECT_NBR)\n","    \n","\n","\n","PERSIST_TO_BUCKET=f\"gs://gaia_data_bucket-{PROJECT_NBR}\"\n","print(\"PERSIST_TO_BUCKET: \",PERSIST_TO_BUCKET)\n","\n","PARQUET_BASE_GCS_URI=f\"{PERSIST_TO_BUCKET}/nyc-taxi-trips-parquet/\"\n","HUDI_BASE_GCS_URI=f\"{PERSIST_TO_BUCKET}/nyc-taxi-trips-hudi/\"\n","\n","\n","DATABASE_NAME=\"taxi_db\"\n","TABLE_NAME=\"nyc_taxi_trips_hudi\"\n","\n"]},{"cell_type":"markdown","id":"a8c7bb69","metadata":{},"source":["### 3. Create database in Apache Hive Metastore\n","The Dataproc cluster was created with an existing Dataproc Metatsore Service referenced as Apache Hive Metastore"]},{"cell_type":"code","execution_count":3,"id":"3fc2afa3","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n"]},{"data":{"text/plain":["DataFrame[]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Create database\n","spark.sql(f\"create database if not exists {DATABASE_NAME};\")"]},{"cell_type":"code","execution_count":4,"id":"0203174a","metadata":{},"outputs":[{"data":{"text/plain":["DataFrame[]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# Drop any existing tables \n","spark.sql(f\"drop table if exists {DATABASE_NAME}.{TABLE_NAME}\")"]},{"cell_type":"markdown","id":"ee7b23fc","metadata":{},"source":["### 4. Read Taxi trips in Parquet format in Cloud Storage and persist as Hudi"]},{"cell_type":"code","execution_count":5,"id":"5c491ae4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Started at 2023-06-28 23:22:31.176740\n"]}],"source":["import datetime\n","startTime = datetime.datetime.now()\n","print(f\"Started at {startTime}\")"]},{"cell_type":"markdown","id":"69c052f5","metadata":{},"source":["#### 4.1. Read Parquet from Cloud Storage"]},{"cell_type":"code","execution_count":6,"id":"9af61bba","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/28 23:23:19 WARN SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n","                                                                                \r"]}],"source":["tripsDF=spark.read.format(\"parquet\").load(PARQUET_BASE_GCS_URI)"]},{"cell_type":"code","execution_count":7,"id":"e36c7954","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/28 23:23:25 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","[Stage 1:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","|taxi_type|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance| fare_amount|  surcharge|    mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_year|trip_month|trip_day|\n","+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","|   yellow|       11|         33|        2|2020-02-14 11:33:08|2020-02-14 11:50:39|                N|      1.0|               107|                186|              2|  1.400000000|11.500000000|0.300000000|0.500000000|      0E-9|        0E-9|                 null|14.800000000|                2|                null|     null|     null|    2020-02-14|                    null|                null|     2020|         2|      14|\n","|   yellow|       12|         38|        2|2020-02-14 12:38:59|2020-02-14 12:56:19|                N|      1.0|               161|                140|              1|  1.830000000|11.500000000|0.300000000|0.500000000|      0E-9|        0E-9|                 null|14.800000000|                2|                null|     null|     null|    2020-02-14|                    null|                null|     2020|         2|      14|\n","+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","only showing top 2 rows\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["tripsDF.show(2)"]},{"cell_type":"markdown","id":"8a89e6aa","metadata":{},"source":["#### 4.2. Persist as Hudi to Cloud Storage"]},{"cell_type":"code","execution_count":8,"id":"f16539ba","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/28 23:23:28 WARN HoodieSparkSqlWriter$: hoodie table at gs://gaia_data_bucket-623600433888/nyc-taxi-trips/hudi-base already exists. Deleting existing data & overwriting with new data.\n","23/06/28 23:23:31 WARN HoodieBackedTableMetadata: Metadata table was not found at path gs://gaia_data_bucket-623600433888/nyc-taxi-trips/hudi-base//.hoodie/metadata\n","23/06/29 00:00:53 WARN DAGScheduler: Broadcasting large task binary with size 1099.7 KiB\n","23/06/29 00:02:52 WARN DAGScheduler: Broadcasting large task binary with size 1100.4 KiB\n","                                                                                \r"]}],"source":["hudi_options = {\n","    'hoodie.database.name': DATABASE_NAME,\n","    'hoodie.table.name': TABLE_NAME,\n","    'hoodie.datasource.write.table.name': TABLE_NAME,\n","    'hoodie.datasource.write.keygenerator.class':'org.apache.hudi.keygen.CustomKeyGenerator',\n","    'hoodie.datasource.write.recordkey.field': 'taxi_type,trip_year,trip_month,trip_day,vendor_id,pickup_location_id,dropoff_location_id',\n","    'hoodie.datasource.write.partitionpath.field': 'trip_year:SIMPLE,trip_month:SIMPLE,trip_day:SIMPLE',\n","    'hoodie.datasource.write.precombine.field': 'pickup_datetime',\n","    'hoodie.datasource.write.hive_style_partitioning': 'true',\n","    'hoodie.partition.metafile.use.base.format': 'true', \n","    'hoodie.datasource.write.drop.partition.columns': 'true'\n","}\n","\n","tripsDF.write.format(\"hudi\"). \\\n","    options(**hudi_options). \\\n","    mode(\"overwrite\"). \\\n","    save(HUDI_BASE_GCS_URI)"]},{"cell_type":"code","execution_count":9,"id":"a5baa7c1","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Completed at 2023-06-29 00:03:05.584754\n"]}],"source":["completionTime = datetime.datetime.now()\n","print(f\"Completed at {completionTime}\")"]},{"cell_type":"markdown","id":"92494db4","metadata":{},"source":["#### 4.3. A quick review of the schema"]},{"cell_type":"code","execution_count":10,"id":"c6b5d376","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- taxi_type: string (nullable = true)\n"," |-- trip_hour: integer (nullable = true)\n"," |-- trip_minute: integer (nullable = true)\n"," |-- vendor_id: string (nullable = true)\n"," |-- pickup_datetime: timestamp (nullable = true)\n"," |-- dropoff_datetime: timestamp (nullable = true)\n"," |-- store_and_forward: string (nullable = true)\n"," |-- rate_code: string (nullable = true)\n"," |-- pickup_location_id: string (nullable = true)\n"," |-- dropoff_location_id: string (nullable = true)\n"," |-- passenger_count: long (nullable = true)\n"," |-- trip_distance: decimal(38,9) (nullable = true)\n"," |-- fare_amount: decimal(38,9) (nullable = true)\n"," |-- surcharge: decimal(38,9) (nullable = true)\n"," |-- mta_tax: decimal(38,9) (nullable = true)\n"," |-- tip_amount: decimal(38,9) (nullable = true)\n"," |-- tolls_amount: decimal(38,9) (nullable = true)\n"," |-- improvement_surcharge: decimal(10,0) (nullable = true)\n"," |-- total_amount: decimal(38,9) (nullable = true)\n"," |-- payment_type_code: string (nullable = true)\n"," |-- congestion_surcharge: decimal(10,0) (nullable = true)\n"," |-- trip_type: string (nullable = true)\n"," |-- ehail_fee: decimal(10,0) (nullable = true)\n"," |-- partition_date: date (nullable = true)\n"," |-- distance_between_service: decimal(38,9) (nullable = true)\n"," |-- time_between_service: long (nullable = true)\n"," |-- trip_year: integer (nullable = true)\n"," |-- trip_month: integer (nullable = true)\n"," |-- trip_day: integer (nullable = true)\n","\n"]}],"source":["tripsDF.printSchema()"]},{"cell_type":"markdown","id":"18963883","metadata":{},"source":["### 5. Register table in Dataproc Metastore Service\n","As part of Terraform for provisioning automation, a managed Hive Metastore was created for you - Dataproc Metastore Service with thrift endpoint."]},{"cell_type":"code","execution_count":11,"id":"89dfd024","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------+\n","|namespace|\n","+---------+\n","|default  |\n","|taxi_db  |\n","+---------+\n","\n"]}],"source":["spark.sql(\"SHOW DATABASES;\").show(truncate=False)"]},{"cell_type":"code","execution_count":12,"id":"d240d681","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/06/29 00:03:08 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.\n"]},{"name":"stdout","output_type":"stream","text":["++\n","||\n","++\n","++\n","\n"]}],"source":["# Create an external table on the Hudi files in the data lake in Cloud Storage\n","spark.sql(f\"CREATE TABLE IF NOT EXISTS {DATABASE_NAME}.{TABLE_NAME} USING hudi LOCATION \\\"{HUDI_BASE_GCS_URI}\\\";\").show()"]},{"cell_type":"markdown","id":"11638e3a","metadata":{},"source":["### 6. Explore the table and data with Spark SQL\n","This requires the table to be registered in the Apache Hive Metastore (Dataproc Metastore Service)."]},{"cell_type":"code","execution_count":13,"id":"b04bcb4a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 54:===================================================>    (51 + 4) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+--------+\n","|count(1)|\n","+--------+\n","|20939415|\n","+--------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(f\"SELECT count(*) FROM {DATABASE_NAME}.{TABLE_NAME}\").show()"]},{"cell_type":"code","execution_count":14,"id":"07a57b20","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 57:=====================================================>  (53 + 2) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+-------------------+--------------------+--------------------+----------------------+--------------------+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","|_hoodie_commit_time|_hoodie_commit_seqno|  _hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|taxi_type|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance| fare_amount|  surcharge|    mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_year|trip_month|trip_day|\n","+-------------------+--------------------+--------------------+----------------------+--------------------+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","|  20230628232328861|20230628232328861...|taxi_type:yellow,...|  trip_year=2019/tr...|c0a18652-6bdc-4f5...|   yellow|       21|         54|        2|2019-03-09 21:54:12|2019-03-09 22:42:22|                N|      1.0|                68|                 17|              1|  6.610000000|32.000000000|0.300000000|0.500000000|      0E-9|        0E-9|                 null|35.800000000|                2|                null|     null|     null|    2019-03-09|                    null|                null|     2019|         3|       9|\n","|  20230628232328861|20230628232328861...|taxi_type:yellow,...|  trip_year=2019/tr...|c0a18652-6bdc-4f5...|   yellow|        8|         22|        2|2019-03-09 08:22:35|2019-03-09 08:41:11|                N|      1.0|               238|                159|              2|  4.660000000|17.000000000|0.300000000|0.500000000|      0E-9|        0E-9|                 null|20.300000000|                1|                null|     null|     null|    2019-03-09|                    null|                null|     2019|         3|       9|\n","+-------------------+--------------------+--------------------+----------------------+--------------------+---------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+---------+----------+--------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(f\"SELECT * FROM {DATABASE_NAME}.{TABLE_NAME} LIMIT 2\").show()"]},{"cell_type":"code","execution_count":15,"id":"bbb31607","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------------------------------+\n","|partition                              |\n","+---------------------------------------+\n","|trip_year=2019/trip_month=1/trip_day=1 |\n","|trip_year=2019/trip_month=1/trip_day=10|\n","|trip_year=2019/trip_month=1/trip_day=11|\n","|trip_year=2019/trip_month=1/trip_day=12|\n","|trip_year=2019/trip_month=1/trip_day=13|\n","|trip_year=2019/trip_month=1/trip_day=14|\n","|trip_year=2019/trip_month=1/trip_day=15|\n","|trip_year=2019/trip_month=1/trip_day=16|\n","|trip_year=2019/trip_month=1/trip_day=17|\n","|trip_year=2019/trip_month=1/trip_day=18|\n","|trip_year=2019/trip_month=1/trip_day=19|\n","|trip_year=2019/trip_month=1/trip_day=2 |\n","|trip_year=2019/trip_month=1/trip_day=20|\n","|trip_year=2019/trip_month=1/trip_day=21|\n","|trip_year=2019/trip_month=1/trip_day=22|\n","|trip_year=2019/trip_month=1/trip_day=23|\n","|trip_year=2019/trip_month=1/trip_day=24|\n","|trip_year=2019/trip_month=1/trip_day=25|\n","|trip_year=2019/trip_month=1/trip_day=26|\n","|trip_year=2019/trip_month=1/trip_day=27|\n","+---------------------------------------+\n","only showing top 20 rows\n","\n"]}],"source":["spark.sql(F\"SHOW PARTITIONS {DATABASE_NAME}.{TABLE_NAME}\").show(truncate=False)"]},{"cell_type":"code","execution_count":16,"id":"ed8be38f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 60:====================================================>   (52 + 3) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+----------+\n","|trip_year|trip_count|\n","+---------+----------+\n","|     2019|   8023712|\n","|     2020|   4179576|\n","|     2022|   4022129|\n","|     2021|   4713998|\n","+---------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(f\"SELECT  trip_year, count(*) trip_count FROM {DATABASE_NAME}.{TABLE_NAME} GROUP BY trip_year\").show()"]},{"cell_type":"code","execution_count":17,"id":"b28d8170","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 63:====================================================>   (52 + 3) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+----------+\n","|taxi_type|trip_count|\n","+---------+----------+\n","|    green|   3967204|\n","|   yellow|  16972211|\n","+---------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(f\"SELECT  taxi_type, count(*) trip_count FROM {DATABASE_NAME}.{TABLE_NAME} GROUP BY taxi_type\").show()"]},{"cell_type":"markdown","id":"c45abdfc","metadata":{},"source":["### 7. Delete the table metadata in the Dataproc Metastore Service (Hive metastore)\n","This is because, we will run the OSS utility that can read Hudi and populate metadata of the Hudi table into a Hive metastore."]},{"cell_type":"code","execution_count":18,"id":"a9e2b158","metadata":{},"outputs":[{"data":{"text/plain":["DataFrame[]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# Drop any existing tables \n","spark.sql(f\"drop table if exists {DATABASE_NAME}.{TABLE_NAME}\")"]},{"cell_type":"markdown","id":"40bdc14b","metadata":{},"source":["This concludes the data generation, proceed to the next module in Github."]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}