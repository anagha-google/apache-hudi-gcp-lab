{"cells":[{"cell_type":"markdown","id":"78d90903","metadata":{},"source":["# Unit 1: Reading Hudi datasets with PySpark\n","In Module 2, we created a Hudi dataset. We also registered the dataset into a Hive Metastore/Dataproc Metastore Service as an external table.\n","\n","In this module:\n","\n","We will review reading Hudi datasets from your data lake using Spark Dataframe API\n","Also review reading via Spark SQL, directly, the previously registered external table in the Apache Hive Metastore/Dataproc Metastore Service\n","At the end of this module, you should know how to read Hudi datasets from Spark."]},{"cell_type":"code","execution_count":1,"id":"d1096055","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/07/07 14:29:55 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["spark = SparkSession.builder \\\n","  .appName(\"Hudi-Learning-Unit-01-pyspark\") \\\n","  .master(\"yarn\")\\\n","  .enableHiveSupport()\\\n","  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n","  .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n","  .getOrCreate()"]},{"cell_type":"code","execution_count":2,"id":"9628d01e","metadata":{"scrolled":false},"outputs":[{"data":{"text/html":["\n","            <div>\n","                <p><b>SparkSession - hive</b></p>\n","                \n","        <div>\n","            <p><b>SparkContext</b></p>\n","\n","            <p><a href=\"http://gaia-dpgce-cpu-623600433888-m.us-central1-a.c.apache-hudi-lab.internal:39587\">Spark UI</a></p>\n","\n","            <dl>\n","              <dt>Version</dt>\n","                <dd><code>v3.3.0</code></dd>\n","              <dt>Master</dt>\n","                <dd><code>yarn</code></dd>\n","              <dt>AppName</dt>\n","                <dd><code>PySparkShell</code></dd>\n","            </dl>\n","        </div>\n","        \n","            </div>\n","        "],"text/plain":["<pyspark.sql.session.SparkSession at 0x7f7eb7f84640>"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["spark"]},{"cell_type":"code","execution_count":11,"id":"578ba5a2","metadata":{},"outputs":[],"source":["PROJECT_ID_OUTPUT=!gcloud config get-value core/project\n","PROJECT_ID=PROJECT_ID_OUTPUT[0]"]},{"cell_type":"code","execution_count":17,"id":"f014aae5","metadata":{},"outputs":[],"source":["PROJECT_NBR_OUTPUT=!gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\n","PROJECT_NBR=PROJECT_NBR_OUTPUT[0]"]},{"cell_type":"code","execution_count":18,"id":"0f4a8679","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Project ID is apache-hudi-lab\n","Project Number is 623600433888\n"]}],"source":["print(f\"Project ID is {PROJECT_ID}\")\n","print(f\"Project Number is {PROJECT_NBR}\")"]},{"cell_type":"code","execution_count":22,"id":"91e51a3b","metadata":{},"outputs":[],"source":["PERSIST_TO_BUCKET = f\"gs://gaia_data_bucket-{PROJECT_NBR}\"\n","PARQUET_BASE_GCS_URI = f\"{PERSIST_TO_BUCKET}/nyc-taxi-trips-parquet/\"\n","HUDI_BASE_GCS_URI = f\"{PERSIST_TO_BUCKET}/nyc-taxi-trips-hudi/\"\n","DATABASE_NAME = \"taxi_db\"\n","TABLE_NAME = \"nyc_taxi_trips_hudi\""]},{"cell_type":"markdown","id":"c768867d","metadata":{},"source":["## 1. Read Hudi dataset from source files in Cloud Storage, with Spark Dataframe API, and analyze with Spark SQL"]},{"cell_type":"code","execution_count":27,"id":"0aba75ec","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["tripsDF = spark.read.format(\"hudi\").load(HUDI_BASE_GCS_URI)"]},{"cell_type":"code","execution_count":28,"id":"da7530cc","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["20939415"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["tripsDF.count()"]},{"cell_type":"code","execution_count":29,"id":"c1d743b8","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["23/07/07 14:47:31 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"]}],"source":["tripsDF.createOrReplaceTempView(\"hudi_taxi_trips_snapshot\")"]},{"cell_type":"code","execution_count":30,"id":"7a42afc2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 10:=====================================================>  (53 + 2) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+----------+\n","|trip_year|trip_count|\n","+---------+----------+\n","|     2019|   8023712|\n","|     2020|   4179576|\n","|     2022|   4022129|\n","|     2021|   4713998|\n","+---------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(\"select trip_year,count(*) as trip_count from hudi_taxi_trips_snapshot group by trip_year\").show()"]},{"cell_type":"markdown","id":"e7eb350a","metadata":{},"source":["## 2. Read previously registered external table on the same Hudi dataset in Hive Metsatore/Dataproc Metastore and analyze with Spark SQL"]},{"cell_type":"code","execution_count":31,"id":"8004104d","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n","[Stage 20:======================================================> (54 + 1) / 55]\r"]},{"name":"stdout","output_type":"stream","text":["+---------+----------+\n","|trip_year|trip_count|\n","+---------+----------+\n","|     2019|   8023712|\n","|     2020|   4179576|\n","|     2021|   4713998|\n","|     2022|   4022129|\n","+---------+----------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["spark.sql(\"select trip_year,count(*) as trip_count from taxi_db.nyc_taxi_trips_hudi group by trip_year\").show()"]},{"cell_type":"markdown","id":"3b815b3a","metadata":{},"source":["This concludes the unit 1. Proceed to the next notebook."]},{"cell_type":"code","execution_count":null,"id":"a5eaa198","metadata":{},"outputs":[{"data":{"application/javascript":["Jupyter.notebook.session.delete();\n"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{},"output_type":"display_data"}],"source":["%%javascript\n","Jupyter.notebook.session.delete();"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}