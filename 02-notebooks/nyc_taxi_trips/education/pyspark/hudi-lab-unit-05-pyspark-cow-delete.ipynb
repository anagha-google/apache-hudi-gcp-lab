{"cells": [{"cell_type": "markdown", "id": "78d90903", "metadata": {}, "source": "# Unit 5: DELETE from COW tables\n\nIn this unit, we will learn delete operations into COW tables.<br>\n\nApache Hudi supports two types of deletes:<br>\nSoft Deletes: This retains the record key and just nulls out the values for all the other fields. The records with nulls in soft deletes are always persisted in storage and never removed.<br>\nHard Deletes: This physically removes any trace of the record from the table. \n"}, {"cell_type": "markdown", "id": "0166b45c", "metadata": {}, "source": "This unit takes about 5 minutes to complete."}, {"cell_type": "markdown", "id": "8781866b-f784-411c-8555-5db002b80d10", "metadata": {}, "source": "### Initialize Spark Session"}, {"cell_type": "code", "execution_count": 1, "id": "d1096055", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/07/30 02:32:42 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}, {"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://gaia-dpgce-cpu-623600433888-m.us-central1-a.c.apache-hudi-lab.internal:37111\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f7683a01030>"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql.functions import lit\nfrom functools import reduce\nfrom pyspark.sql.types import LongType\nimport pyspark.sql.functions as F\nfrom datetime import datetime\n\nspark = SparkSession.builder \\\n  .appName(\"Hudi-Learning-Unit-05-PySpark\") \\\n  .master(\"yarn\")\\\n  .enableHiveSupport()\\\n  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n  .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n  .getOrCreate()\n\nspark"}, {"cell_type": "markdown", "id": "adaa90d1", "metadata": {}, "source": "### Declare & define base variables"}, {"cell_type": "code", "execution_count": 2, "id": "578ba5a2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Project ID is apache-hudi-lab\nProject Number is 623600433888\n"}], "source": "PROJECT_ID_OUTPUT=!gcloud config get-value core/project\nPROJECT_ID=PROJECT_ID_OUTPUT[0]\nPROJECT_NBR_OUTPUT=!gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\nPROJECT_NBR=PROJECT_NBR_OUTPUT[0]\nprint(f\"Project ID is {PROJECT_ID}\")\nprint(f\"Project Number is {PROJECT_NBR}\")\n\nPERSIST_TO_BUCKET = f\"gs://gaia_data_bucket-{PROJECT_NBR}\"\nHUDI_COW_BASE_GCS_URI = f\"{PERSIST_TO_BUCKET}/nyc-taxi-trips-hudi-cow\"\nDATABASE_NAME = \"taxi_db\"\nCOW_TABLE_NAME = \"nyc_taxi_trips_hudi_cow\"\nTRIP_DATE='2021-01-31'"}, {"cell_type": "markdown", "id": "a192314f-9014-4cac-8e4f-45bea6ea8d43", "metadata": {}, "source": "## 1. \"Soft Delete\" a record\nSoft Delete - retains the record key and just nulls out the values for all the other fields. The records with nulls in soft deletes are always persisted in storage and never removed.<br>\n"}, {"cell_type": "markdown", "id": "0570ad8c-ccf3-481a-ace9-4cdc4ba13fea", "metadata": {}, "source": "### 1.1. Record count prior to soft delete\nThis retains the record key and just nulls out the values for all the other fields. The records with nulls in soft deletes are always persisted in storage and never removed."}, {"cell_type": "code", "execution_count": 3, "id": "7ddd7177-3bdf-445c-82b3-5c42f92b19bd", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n23/07/30 02:32:47 WARN GhfsStorageStatistics: Detected potential high latency for operation op_open. latencyMs=110; previousMaxLatencyMs=0; operationCount=1; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/hoodie.properties\n[Stage 3:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "RECORD_COUNT_PRIOR_TO_DELETE=32604\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "RECORD_COUNT_PRIOR_TO_DELETE=spark.sql(f\"SELECT COUNT(*) as trip_count FROM {DATABASE_NAME}.{COW_TABLE_NAME} WHERE trip_date=\\\"{TRIP_DATE}\\\"\").collect()[0][0]\nprint(f\"RECORD_COUNT_PRIOR_TO_DELETE={RECORD_COUNT_PRIOR_TO_DELETE}\")"}, {"cell_type": "markdown", "id": "d0c7db8c-7105-4e65-89ba-bbc6ac3f6af1", "metadata": {}, "source": "### 1.2. Files before delete"}, {"cell_type": "code", "execution_count": 4, "id": "90b12bad-880b-4fc9-900f-382046bb3495", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/.hoodie_partition_metadata.parquet#1690682394857386  metageneration=1\n   1.3 MiB  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/8c11c11f-7e53-4b28-a223-eebb4bace8fc-0_103-57-15632_20230729055658662.parquet#1690682394893869  metageneration=1\nTOTAL: 2 objects, 1358778 bytes (1.3 MiB)\n"}], "source": "# GCS parquet file listing prior to insert\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=$TRIP_DATE"}, {"cell_type": "markdown", "id": "ab33d9cc-80df-4c29-84cd-8c71314ec689", "metadata": {}, "source": "### 1.3. Identify a record to delete"}, {"cell_type": "code", "execution_count": 5, "id": "880818bd-4e03-4b28-a06a-9d2db9da2636", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "DELETE_CANDIDATE_TRIP_ID=438086925068\n"}, {"name": "stderr", "output_type": "stream", "text": "23/07/30 02:33:16 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n[Stage 7:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount|  surcharge|    mta_tax| tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|     trip_id| trip_date|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|  20230729055658662|20230729055658662...|      438086925068|  trip_date=2021-01-31|8c11c11f-7e53-4b2...|    green|     2021|         1|      31|       19|         27|        2|2021-01-31 19:27:28|2021-01-31 19:32:46|                N|      1.0|                74|                 75|              1|  1.270000000|6.500000000|0.300000000|0.500000000|1.460000000|        0E-9|                 null| 8.760000000|              1.0|                null|      1.0|     null|    2021-01-31|                    null|                null|438086925068|2021-01-31|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Select a trip ID to delete\nDELETE_CANDIDATE_TRIP_ID=spark.sql(f\"SELECT trip_id  FROM {DATABASE_NAME}.{COW_TABLE_NAME} WHERE trip_date=\\\"{TRIP_DATE}\\\" LIMIT 1\").collect()[0][0]\nprint(f\"DELETE_CANDIDATE_TRIP_ID={DELETE_CANDIDATE_TRIP_ID}\")\n\n# Create a dataframe with the record\ndeleteTripDFCow=spark.sql(f\"SELECT * FROM {DATABASE_NAME}.{COW_TABLE_NAME} WHERE trip_date=\\\"{TRIP_DATE}\\\" AND trip_id={DELETE_CANDIDATE_TRIP_ID}\")\n\n# Here is the \"before\" the soft delete\ndeleteTripDFCow.show()"}, {"cell_type": "markdown", "id": "553463e6-bc7d-4248-9994-5d6dcd0483c8", "metadata": {}, "source": "### 1.4. Prepare for soft delete"}, {"cell_type": "code", "execution_count": 6, "id": "8dd2539e-d5fd-424d-a945-bcd2489c5538", "metadata": {}, "outputs": [], "source": "hudi_soft_delete_options = {\n            'hoodie.database.name': DATABASE_NAME,\n            'hoodie.table.name': COW_TABLE_NAME,\n            'hoodie.datasource.write.table.name': COW_TABLE_NAME,\n            'hoodie.datasource.write.table.type': 'COPY_ON_WRITE',\n            'hoodie.datasource.write.recordkey.field': 'trip_id',\n            'hoodie.datasource.write.partitionpath.field': 'trip_date',\n            'hoodie.datasource.write.precombine.field': 'pickup_datetime',\n            'hoodie.datasource.write.hive_style_partitioning': 'true',\n            'hoodie.partition.metafile.use.base.format': 'true', \n            'hoodie.datasource.write.operation': 'upsert',\n            'hoodie.datasource.write.drop.partition.columns': 'true',\n            'hoodie.upsert.shuffle.parallelism': 2, \n            'hoodie.combine.before.delete': 'false'\n}"}, {"cell_type": "code", "execution_count": 7, "id": "0f69df6a-e4d9-4afe-9102-e00c8a315100", "metadata": {}, "outputs": [], "source": "meta_columns = [\"_hoodie_commit_time\", \"_hoodie_commit_seqno\", \"_hoodie_record_key\", \\\n  \"_hoodie_trip_date\", \"_hoodie_file_name\"]\nexcluded_columns = meta_columns + [\"pickup_datetime\",\"trip_id\"]"}, {"cell_type": "code", "execution_count": 8, "id": "67824f2f-69b6-4201-b632-1494ec4653dd", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+----------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+---------+-------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+---------+\n|_hoodie_commit_time|_hoodie_commit_seqno   |_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name                                                            |taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|pickup_datetime    |dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount|surcharge|mta_tax|tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_id     |trip_date|\n+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+----------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+---------+-------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+---------+\n|20230729055658662  |20230729055658662_103_0|438086925068      |null                  |8c11c11f-7e53-4b28-a223-eebb4bace8fc-0_103-57-15632_20230729055658662.parquet|null     |null     |null      |null    |null     |null       |null     |2021-01-31 19:27:28|null            |null             |null     |null              |null               |null           |null         |null       |null     |null   |null      |null        |null                 |null        |null             |null                |null     |null     |null          |null                    |null                |438086925068|null     |\n+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+----------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+---------+-------+----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+---------+\n\n"}], "source": "# Prepare for the soft delete by ensuring the appropriate fields are nullified\nnullify_columns = list(filter(lambda field: field[0] not in excluded_columns, \\\n  list(map(lambda field: (field.name, field.dataType), deleteTripDFCow.schema.fields))))\n\nsoftDeleteTripDFCow = reduce(lambda df,col: df.withColumn(col[0], lit(None).cast(col[1])), \\\n  nullify_columns, reduce(lambda df,col: df.drop(col[0]), meta_columns, deleteTripDFCow))\n\n# Lets look at the record we want to soft delete\nsoftDeleteTripDFCow.show(truncate=False)"}, {"cell_type": "markdown", "id": "629475a2-1920-4054-ad0b-0f8ad742d865", "metadata": {}, "source": "In contrast, the original record-"}, {"cell_type": "code", "execution_count": 9, "id": "afe1f77b-498d-4039-bfb9-2982bbea9448", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount|  surcharge|    mta_tax| tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|     trip_id| trip_date|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|  20230729055658662|20230729055658662...|      438086925068|  trip_date=2021-01-31|8c11c11f-7e53-4b2...|    green|     2021|         1|      31|       19|         27|        2|2021-01-31 19:27:28|2021-01-31 19:32:46|                N|      1.0|                74|                 75|              1|  1.270000000|6.500000000|0.300000000|0.500000000|1.460000000|        0E-9|                 null| 8.760000000|              1.0|                null|      1.0|     null|    2021-01-31|                    null|                null|438086925068|2021-01-31|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}], "source": "deleteTripDFCow.show()"}, {"cell_type": "markdown", "id": "57998d6a-3856-4676-a80e-bceed3809eb4", "metadata": {}, "source": "### 1.5. Execute the soft delete"}, {"cell_type": "code", "execution_count": 10, "id": "f1be1efc-6db7-497d-a890-ff3ad7ec7b04", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/07/30 02:33:24 WARN GhfsStorageStatistics: Detected potential high latency for operation stream_write_close_operations. latencyMs=103; previousMaxLatencyMs=0; operationCount=1; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/20230730023322415.deltacommit.requested\n23/07/30 02:33:31 WARN GhfsStorageStatistics: Detected potential high latency for operation stream_write_close_operations. latencyMs=118; previousMaxLatencyMs=103; operationCount=2; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/20230730023322415.deltacommit.inflight\n23/07/30 02:33:33 WARN GhfsStorageStatistics: Detected potential high latency for operation op_create. latencyMs=104; previousMaxLatencyMs=82; operationCount=4; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/.temp/20230730023322415/MARKERS.type\n23/07/30 02:33:33 WARN GhfsStorageStatistics: Detected potential high latency for operation stream_write_close_operations. latencyMs=145; previousMaxLatencyMs=118; operationCount=3; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/.temp/20230730023322415/MARKERS.type\n23/07/30 02:33:41 WARN GhfsStorageStatistics: Detected potential high latency for operation op_delete. latencyMs=115; previousMaxLatencyMs=0; operationCount=1; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/metadata/.hoodie/.temp/20230730022946927001\n                                                                                \r"}], "source": "# Simply upsert the table after setting all the fields to null, except the record key, partition key and precombine key fields \nsoftDeleteTripDFCow.write.format(\"hudi\"). \\\n  options(**hudi_soft_delete_options). \\\n  mode(\"append\"). \\\n  save(HUDI_COW_BASE_GCS_URI)"}, {"cell_type": "code", "execution_count": 11, "id": "68841e33-a03b-48c6-81b4-9b496b5a7829", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "++\n||\n++\n++\n\n"}], "source": "spark.sql(f\"REFRESH TABLE {DATABASE_NAME}.{COW_TABLE_NAME};\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 12, "id": "fa8182dc-b21b-4874-a5b2-3e3a90951bac", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "RECORD_COUNT_PRIOR_TO_DELETE=32604\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 51:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+----------+\n|trip_count|\n+----------+\n|32604     |\n+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "print(f\"RECORD_COUNT_PRIOR_TO_DELETE={RECORD_COUNT_PRIOR_TO_DELETE}\")\n\n# Lets do a count after we soft delete - should be same as before\nspark.sql(f\"SELECT COUNT(*) as trip_count FROM {DATABASE_NAME}.{COW_TABLE_NAME} WHERE trip_date=\\\"{TRIP_DATE}\\\" \").show(truncate=False)"}, {"cell_type": "code", "execution_count": 13, "id": "3c74b3ad-ea85-486f-a8af-6ef985af81ad", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 54:>                                                         (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|438086925068|green    |2        |2021-01-31 19:27:28|2021-01-31 19:32:46|74                |75                 |2021-01-31|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Lets search for the record we attempted to soft-delete\nspark.sql(f\"SELECT trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date \" \\\n          f\" FROM {DATABASE_NAME}.{COW_TABLE_NAME} \" \\\n          f\" WHERE trip_date=\\\"{TRIP_DATE}\\\" AND trip_id={DELETE_CANDIDATE_TRIP_ID}\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 14, "id": "6262ddfc-a02a-48ef-9bdd-697dc0028403", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/.hoodie_partition_metadata.parquet#1690682394857386  metageneration=1\n   1.3 MiB  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/8c11c11f-7e53-4b28-a223-eebb4bace8fc-0_103-57-15632_20230729055658662.parquet#1690682394893869  metageneration=1\nTOTAL: 2 objects, 1358778 bytes (1.3 MiB)\n"}], "source": "# Lets check to see if there is a new file\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=$TRIP_DATE"}, {"cell_type": "markdown", "id": "f99d2af8-7b30-446d-affd-3076cc78b5cc", "metadata": {}, "source": "#### How does soft delete help?\nWhen you have to scrub data but not lose the trace of the record, you can nullify the columns, and avoid reflection of it in say, aggregation operations on the table. "}, {"cell_type": "code", "execution_count": 15, "id": "83e29fce-40d7-4d5f-aaf8-07f3ae3e7879", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|     trip_id|taxi_type|vendor_id|    pickup_datetime|   dropoff_datetime|pickup_location_id|dropoff_location_id| trip_date|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|438086925068|    green|        2|2021-01-31 19:27:28|2021-01-31 19:32:46|                74|                 75|2021-01-31|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Read from source in GCS\nspark.read.format(\"hudi\").load(HUDI_COW_BASE_GCS_URI).createOrReplaceTempView(\"hudi_trips_snapshot\")\n\n# This should return the same total count as before\nspark.sql(f\"SELECT trip_id,trip_date FROM hudi_trips_snapshot WHERE trip_date=\\\"{TRIP_DATE}\\\"\").count()\n\n# Search for the record\nspark.sql(f\"SELECT trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date FROM hudi_trips_snapshot \" \\\n          f\"WHERE trip_date=\\\"{TRIP_DATE}\\\" and trip_id={DELETE_CANDIDATE_TRIP_ID}\").show()"}, {"cell_type": "markdown", "id": "d1071e59-5845-4d76-94a9-7768e94a4966", "metadata": {}, "source": "### 3.2. Hard Delete\nThis physically removes any trace of the record from the table. "}, {"cell_type": "code", "execution_count": 16, "id": "7277ca1f-dbdb-4180-8307-011f490c31a1", "metadata": {}, "outputs": [], "source": "hudi_hard_delete_options = {\n            'hoodie.database.name': DATABASE_NAME,\n            'hoodie.table.name': COW_TABLE_NAME,\n            'hoodie.datasource.write.table.name': COW_TABLE_NAME,\n            'hoodie.datasource.write.table.type': 'COPY_ON_WRITE',\n            'hoodie.datasource.write.recordkey.field': 'trip_id',\n            'hoodie.datasource.write.partitionpath.field': 'trip_date',\n            'hoodie.datasource.write.precombine.field': 'pickup_datetime',\n            'hoodie.datasource.write.hive_style_partitioning': 'true',\n            'hoodie.partition.metafile.use.base.format': 'true', \n            'hoodie.datasource.write.drop.partition.columns': 'true',\n            'hoodie.datasource.write.operation': 'delete',\n            'hoodie.combine.before.delete': 'false'\n}\n"}, {"cell_type": "code", "execution_count": 17, "id": "4fbfddaf-d5d2-486e-952e-365ac72b140c", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Simply append to the table - the delete setting in the options will remove physical trace of the record\nsoftDeleteTripDFCow.write.format(\"hudi\"). \\\n  options(**hudi_hard_delete_options). \\\n  mode(\"append\"). \\\n  save(HUDI_COW_BASE_GCS_URI)\n"}, {"cell_type": "code", "execution_count": 20, "id": "fca22af9-0b88-4d79-a1cd-71aaf7c3bdc2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "++\n||\n++\n++\n\n"}], "source": "# Refresh Hive Metsatore Metadata\nspark.sql(f\"REFRESH TABLE {DATABASE_NAME}.{COW_TABLE_NAME};\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 21, "id": "000179cf-cfd9-4267-b5aa-52025b758d26", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 118:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|_hoodie_commit_time|_hoodie_commit_seqno   |_hoodie_record_key|_hoodie_partition_path|_hoodie_file_name                                                            |taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|pickup_datetime    |dropoff_datetime   |store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount|surcharge  |mta_tax    |tip_amount |tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_id     |trip_date |\n+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|20230729055658662  |20230729055658662_103_0|438086925068      |trip_date=2021-01-31  |8c11c11f-7e53-4b28-a223-eebb4bace8fc-0_103-57-15632_20230729055658662.parquet|green    |2021     |1         |31      |19       |27         |2        |2021-01-31 19:27:28|2021-01-31 19:32:46|N                |1.0      |74                |75                 |1              |1.270000000  |6.500000000|0.300000000|0.500000000|1.460000000|0E-9        |null                 |8.760000000 |1.0              |null                |1.0      |null     |2021-01-31    |null                    |null                |438086925068|2021-01-31|\n+-------------------+-----------------------+------------------+----------------------+-----------------------------------------------------------------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+-----------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Lets search for the record we attempted to hard delete\nspark.sql(f\"SELECT * FROM {DATABASE_NAME}.{COW_TABLE_NAME} WHERE trip_date=\\\"{TRIP_DATE}\\\" AND trip_id={DELETE_CANDIDATE_TRIP_ID}\").show(truncate=False)"}, {"cell_type": "code", "execution_count": 22, "id": "3bb70f09-81a4-47e0-8b69-c100952a3472", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/.hoodie_partition_metadata.parquet#1690682394857386  metageneration=1\n   1.3 MiB  2023-07-30T01:59:54Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2021-01-31/8c11c11f-7e53-4b28-a223-eebb4bace8fc-0_103-57-15632_20230729055658662.parquet#1690682394893869  metageneration=1\nTOTAL: 2 objects, 1358778 bytes (1.3 MiB)\n"}, {"name": "stderr", "output_type": "stream", "text": "ERROR:root:Exception while sending command.\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 516, in send_command\n    raise Py4JNetworkError(\"Answer from Java side is empty\")\npy4j.protocol.Py4JNetworkError: Answer from Java side is empty\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/clientserver.py\", line 539, in send_command\n    raise Py4JNetworkError(\npy4j.protocol.Py4JNetworkError: Error while sending or receiving\n/usr/lib/spark/python/pyspark/context.py:561: RuntimeWarning: Unable to cleanly shutdown Spark JVM process. It is possible that the process has crashed, been killed or may also be in a zombie state.\n  warnings.warn(\n"}], "source": "# Lets check to see if there is a new file\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=$TRIP_DATE"}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}, "toc-showcode": true}, "nbformat": 4, "nbformat_minor": 5}