{"cells": [{"cell_type": "markdown", "id": "78d90903", "metadata": {}, "source": "# Unit 4: UPSERT into COW tables\nIn this unit, we will learn upsert operations into COW tables.<br>\nThis unit takes about 5 minutes to complete.\n"}, {"cell_type": "markdown", "id": "8781866b-f784-411c-8555-5db002b80d10", "metadata": {}, "source": "### Initialize Spark Session"}, {"cell_type": "code", "execution_count": 1, "id": "d1096055", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/08/01 03:27:24 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"}, {"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://gaia-dpgce-cpu-623600433888-m.us-central1-a.c.apache-hudi-lab.internal:38623\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f8c9d10efe0>"}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql.functions import lit\nfrom functools import reduce\nfrom pyspark.sql.types import LongType\nimport pyspark.sql.functions as F\nfrom datetime import datetime\n\n\nspark = SparkSession.builder \\\n  .appName(\"Hudi-Learning-Unit-04-PySpark\") \\\n  .master(\"yarn\") \\\n  .enableHiveSupport() \\\n  .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n  .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.hudi.catalog.HoodieCatalog\") \\\n  .config(\"spark.sql.extensions\", \"org.apache.spark.sql.hudi.HoodieSparkSessionExtension\") \\\n  .getOrCreate()\n\nspark"}, {"cell_type": "markdown", "id": "adaa90d1", "metadata": {}, "source": "### Declare & define variables"}, {"cell_type": "code", "execution_count": 2, "id": "578ba5a2", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Project ID is apache-hudi-lab\nProject number is 623600433888\nProject location is us-central1\nHudi Base Cow Table GCS URI is gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow\nDataproc Metastore Service thrift URI is thrift://10.60.192.28:9080\n"}], "source": "PROJECT_ID_OUTPUT=!gcloud config get-value core/project \nPROJECT_ID=PROJECT_ID_OUTPUT[0]\nPROJECT_NBR_OUTPUT=!gcloud projects describe $PROJECT_ID --format=\"value(projectNumber)\"\nPROJECT_NBR=PROJECT_NBR_OUTPUT[0]\nLOCATION=\"us-central1\" #Update as needed\nHUDI_COW_BASE_GCS_URI = f\"gs://gaia_data_bucket-{PROJECT_NBR}/nyc-taxi-trips-hudi-cow\"\nDATAPROC_METASTORE_THRIFT_URI_LIST=!gcloud metastore services list --location $LOCATION | grep thrift | cut -d' ' -f11\nDATAPROC_METASTORE_THRIFT_URI=DATAPROC_METASTORE_THRIFT_URI_LIST[0]\n\nprint(f\"Project ID is {PROJECT_ID}\")\nprint(f\"Project number is {PROJECT_NBR}\")\nprint(f\"Project location is {LOCATION}\")\nprint(f\"Hudi Base Cow Table GCS URI is {HUDI_COW_BASE_GCS_URI}\")\nprint(f\"Dataproc Metastore Service thrift URI is {DATAPROC_METASTORE_THRIFT_URI}\")\n"}, {"cell_type": "markdown", "id": "eb8cb7af-22a9-4465-b8ed-de2e4627c3e6", "metadata": {}, "source": "## 1. Upsert into Hudi"}, {"cell_type": "markdown", "id": "4e63b74b-e299-4f48-bb26-e6db78a8ad26", "metadata": {}, "source": "Here we will learn how to an insert a new record & and update existing record(s) via the upsert operation.<br>\nJust like we did in the previous exercise, we will take some existing record and increment the hour and use in this lab unit.<br>\n\nInsert candidate trip_date to clone & morph: '2019-03-15' <br>\nUpdate candidate trip_date to clone & morph: '2019-01-18'<br>"}, {"cell_type": "markdown", "id": "8e14ed76-68dc-405d-98b8-843150a0d5c9", "metadata": {}, "source": "### 1.1. Trips to clone and use for the lab unit\n"}, {"cell_type": "code", "execution_count": 3, "id": "192a3ebe-098f-42fc-a978-b480719f5b65", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n23/08/01 03:27:30 WARN GhfsStorageStatistics: Detected potential high latency for operation op_open. latencyMs=126; previousMaxLatencyMs=0; operationCount=1; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/hoodie.properties\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "INSERT_CLONE_CANDIDATE_TRIP_ID: 764504188335\nUPDATE_CLONE_CANDIDATE_TRIP_ID: 695784702201\n"}], "source": "INSERT_TRIP_DATE='2019-03-10'\nINSERT_CLONE_CANDIDATE_TRIP_ID=spark.sql(f\"select trip_id  from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-03-10' AND trip_hour < 12 LIMIT 1\").collect()[0][0]\nprint(f\"INSERT_CLONE_CANDIDATE_TRIP_ID: {INSERT_CLONE_CANDIDATE_TRIP_ID}\")\n\nUPDATE_TRIP_DATE='2019-01-15'\nUPDATE_CANDIDATE_TRIP_ID=spark.sql(f\"select trip_id  from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-01-15' AND trip_hour < 12 LIMIT 1\").collect()[0][0]\nprint(f\"UPDATE_CLONE_CANDIDATE_TRIP_ID: {UPDATE_CANDIDATE_TRIP_ID}\")"}, {"cell_type": "markdown", "id": "8b608893-d788-4637-8f0a-f70afc87417d", "metadata": {}, "source": "### 1.2. Generate unique Trip ID for the insert "}, {"cell_type": "code", "execution_count": 4, "id": "720b96ed-ef17-44bf-8c90-a209910d1bd6", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 5:============================================>              (3 + 1) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "Unique Trip ID generated for the trip to be inserted is: 1786706865009\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "TO_BE_INSERTED_TRIP_ID=spark.sql(f\"SELECT max(trip_id) FROM taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-03-10'\").collect()[0][0] + 1\nprint(f\"Unique Trip ID generated for the trip to be inserted is: {TO_BE_INSERTED_TRIP_ID}\")"}, {"cell_type": "markdown", "id": "4c29ecbf-63d2-437f-a6a9-d09ec36930f4", "metadata": {}, "source": "### 1.3. Insert dataframe creation"}, {"cell_type": "code", "execution_count": 5, "id": "177dd65a-15d6-4740-b383-e3acb10a0e5f", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/08/01 03:27:59 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance| fare_amount|  surcharge|    mta_tax| tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|     trip_id| trip_date|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|  20230731203923454|20230731203923454...|      764504188335|  trip_date=2019-03-10|659d68c7-734c-460...|   yellow|     2019|         3|      10|        9|         44|        2|2019-03-10 09:44:09|2019-03-10 09:59:03|                N|      1.0|               141|                112|              6|  3.810000000|15.000000000|0.300000000|0.500000000|3.660000000|        0E-9|                 null|21.960000000|                1|                null|     null|     null|    2019-03-10|                    null|                null|764504188335|2019-03-10|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}], "source": "# Original record\ninsertCandidateTripDFCow=spark.sql(f\"SELECT * FROM taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-03-10' and trip_id={INSERT_CLONE_CANDIDATE_TRIP_ID}\")\ninsertCandidateTripDFCow.show()\n"}, {"cell_type": "code", "execution_count": 6, "id": "f9d9d168-e6db-441d-a786-8cd80f40326d", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|pickup_datetime    |dropoff_datetime   |store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount |surcharge  |mta_tax    |tip_amount |tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_id      |trip_date |\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n|yellow   |2019     |3         |10      |14       |44         |2        |2019-03-10 14:44:09|2019-03-10 14:59:03|N                |1.0      |141               |112                |6              |3.810000000  |15.000000000|0.300000000|0.500000000|3.660000000|0E-9        |null                 |21.960000000|1                |null                |null     |null     |2019-03-10    |null                    |null                |1786706865009|2019-03-10|\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n\n"}], "source": "# Generate record to insert based off of the above record - increment all the date column by 5 hours\ninsertTripDFCow = insertCandidateTripDFCow.withColumn('pickup_datetime', insertCandidateTripDFCow.pickup_datetime + F.expr('INTERVAL 5 HOURS')) \\\n                                    .withColumn('dropoff_datetime', insertCandidateTripDFCow.dropoff_datetime + F.expr('INTERVAL 5 HOURS')) \\\n                                    .withColumn('trip_hour', insertCandidateTripDFCow.trip_hour + 5) \\\n                                    .withColumn('trip_id', lit(TO_BE_INSERTED_TRIP_ID)) \\\n                                    .drop(\"_hoodie_commit_time\") \\\n                                    .drop(\"_hoodie_commit_seqno\") \\\n                                    .drop(\"_hoodie_record_key\") \\\n                                    .drop(\"_hoodie_partition_path\") \\\n                                    .drop(\"_hoodie_file_name\")\n\ninsertTripDFCow.show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 7, "id": "74e0dc66-5e49-4190-9285-37b3f6e11a18", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|764504188335|yellow   |2        |2019-03-10 09:44:09|2019-03-10 09:59:03|141               |112                |2019-03-10|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Original record with just a few fields\nspark.sql(f\"SELECT trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date \" \\\n          f\" FROM taxi_db.nyc_taxi_trips_hudi_cow \"\\\n          f\" WHERE trip_date='2019-03-10' and trip_id={INSERT_CLONE_CANDIDATE_TRIP_ID}\") \\\n        .show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 8, "id": "6d01133d-7e66-450a-a683-ab64c09da6d3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|trip_id      |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|1786706865009|yellow   |2        |2019-03-10 14:44:09|2019-03-10 14:59:03|141               |112                |2019-03-10|\n+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# The record we want to insert - note its pickup_datetime and dropoff_datetime are different\ninsertTripDFCow.select(\"trip_id\",\"taxi_type\",\"vendor_id\",\"pickup_datetime\",\"dropoff_datetime\",\"pickup_location_id\",\"dropoff_location_id\",\"trip_date\") \\\n               .show(truncate=False)\n"}, {"cell_type": "markdown", "id": "bd2bd2f0-f937-4925-920b-a246a6956432", "metadata": {}, "source": "### 1.4. Update record generation"}, {"cell_type": "code", "execution_count": 9, "id": "bd63d505-40cc-41a6-af20-2b72cf2f3efc", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|_hoodie_commit_time|_hoodie_commit_seqno|_hoodie_record_key|_hoodie_partition_path|   _hoodie_file_name|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|    pickup_datetime|   dropoff_datetime|store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance| fare_amount|  surcharge|    mta_tax| tip_amount|tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|     trip_id| trip_date|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|  20230731203923454|20230731203923454...|      695784702201|  trip_date=2019-01-15|ab386b38-4ae1-4e5...|   yellow|     2019|         1|      15|       10|          0|        1|2019-01-15 10:00:30|2019-01-15 10:49:46|                N|      1.0|                68|                141|              0|  3.400000000|28.000000000|0.300000000|0.500000000|7.200000000|        0E-9|                 null|36.000000000|                1|                null|     null|     null|    2019-01-15|                    null|                null|695784702201|2019-01-15|\n+-------------------+--------------------+------------------+----------------------+--------------------+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Original record\nupdateCandidateTripDFCow=spark.sql(f\"SELECT * FROM taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-01-15' AND trip_id={UPDATE_CANDIDATE_TRIP_ID}\")\nupdateCandidateTripDFCow.show()\n"}, {"cell_type": "code", "execution_count": 10, "id": "0f75df4c-51ce-46a7-ada1-219f45636da8", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|pickup_datetime    |dropoff_datetime   |store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount |surcharge  |mta_tax    |tip_amount |tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_id     |trip_date |\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n|yellow   |2019     |1         |15      |15       |0          |1        |2019-01-15 11:00:30|2019-01-15 11:49:46|N                |1.0      |68                |141                |0              |3.400000000  |28.000000000|0.300000000|0.500000000|7.200000000|0E-9        |null                 |36.000000000|1                |null                |null     |null     |2019-01-15    |null                    |null                |695784702201|2019-01-15|\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+------------+----------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Generate dataframe that updates the above record\nupdateTripDFCow = updateCandidateTripDFCow.withColumn('pickup_datetime', updateCandidateTripDFCow.pickup_datetime + F.expr('INTERVAL 1 HOURS')) \\\n                                    .withColumn('dropoff_datetime', updateCandidateTripDFCow.dropoff_datetime + F.expr('INTERVAL 1 HOURS')) \\\n                                    .withColumn('trip_hour', updateCandidateTripDFCow.trip_hour + 5) \\\n                                    .drop(\"_hoodie_commit_time\") \\\n                                    .drop(\"_hoodie_commit_seqno\") \\\n                                    .drop(\"_hoodie_record_key\") \\\n                                    .drop(\"_hoodie_file_name\") \\\n                                    .drop(\"_hoodie_partition_path\")\n\n# The full record we will update\nupdateTripDFCow.show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 11, "id": "657f4d5a-51f8-4fc9-ab31-5df04f6d03f3", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+-------------------+-----------------------+----------------------------------------------------------------------------+\n|trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |_hoodie_commit_time|_hoodie_commit_seqno   |_hoodie_file_name                                                           |\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+-------------------+-----------------------+----------------------------------------------------------------------------+\n|695784702201|yellow   |1        |2019-01-15 10:00:30|2019-01-15 10:49:46|68                |141                |2019-01-15|20230731203923454  |20230731203923454_478_1|ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_478-19-9440_20230731203923454.parquet|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+-------------------+-----------------------+----------------------------------------------------------------------------+\n\n"}], "source": "# Original record prior to update - just a few columns for readbility\nspark.sql(f\"SELECT trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date \" \\\n          \",_hoodie_commit_time,_hoodie_commit_seqno,_hoodie_file_name\" \\\n          f\" FROM taxi_db.nyc_taxi_trips_hudi_cow \"\\\n          f\" WHERE trip_date='2019-01-15' AND trip_id={UPDATE_CANDIDATE_TRIP_ID}\") \\\n        .show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 12, "id": "716dccc7-ee35-417b-94a7-839c7a25d803", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|695784702201|yellow   |1        |2019-01-15 11:00:30|2019-01-15 11:49:46|68                |141                |2019-01-15|\n+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Updated details of the above record - note its pickup_datetime and dropoff_datetime are different\nupdateTripDFCow.select(\"trip_id\",\"taxi_type\",\"vendor_id\",\"pickup_datetime\",\"dropoff_datetime\",\"pickup_location_id\",\"dropoff_location_id\",\"trip_date\") \\\n               .show(truncate=False)\n"}, {"cell_type": "markdown", "id": "3a70a400-80de-4554-a602-fcd7e73a0d58", "metadata": {}, "source": "### 1.5. Prepare to upsert"}, {"cell_type": "code", "execution_count": 13, "id": "4ddb13b1-8ff7-444a-a17c-c738c3cc18ad", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n|taxi_type|trip_year|trip_month|trip_day|trip_hour|trip_minute|vendor_id|pickup_datetime    |dropoff_datetime   |store_and_forward|rate_code|pickup_location_id|dropoff_location_id|passenger_count|trip_distance|fare_amount |surcharge  |mta_tax    |tip_amount |tolls_amount|improvement_surcharge|total_amount|payment_type_code|congestion_surcharge|trip_type|ehail_fee|partition_date|distance_between_service|time_between_service|trip_id      |trip_date |\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n|yellow   |2019     |3         |10      |14       |44         |2        |2019-03-10 14:44:09|2019-03-10 14:59:03|N                |1.0      |141               |112                |6              |3.810000000  |15.000000000|0.300000000|0.500000000|3.660000000|0E-9        |null                 |21.960000000|1                |null                |null     |null     |2019-03-10    |null                    |null                |1786706865009|2019-03-10|\n|yellow   |2019     |1         |15      |15       |0          |1        |2019-01-15 11:00:30|2019-01-15 11:49:46|N                |1.0      |68                |141                |0              |3.400000000  |28.000000000|0.300000000|0.500000000|7.200000000|0E-9        |null                 |36.000000000|1                |null                |null     |null     |2019-01-15    |null                    |null                |695784702201 |2019-01-15|\n+---------+---------+----------+--------+---------+-----------+---------+-------------------+-------------------+-----------------+---------+------------------+-------------------+---------------+-------------+------------+-----------+-----------+-----------+------------+---------------------+------------+-----------------+--------------------+---------+---------+--------------+------------------------+--------------------+-------------+----------+\n\n"}], "source": "# Lets union the dataframes\nupsertTripDFCow = insertTripDFCow.union(updateTripDFCow)\n# Quick visual \nupsertTripDFCow.show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 14, "id": "5e62553d-5f8a-4ef6-a8e9-d86bff524630", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Trip count before insert: 245530\n"}], "source": "# Capture record count before insert\nTRIP_COUNT_BEFORE_INSERT=spark.sql(f\"select count(*)  from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-03-10'\").collect()[0][0]\nprint(f\"Trip count before insert: {TRIP_COUNT_BEFORE_INSERT}\")\n"}, {"cell_type": "code", "execution_count": 15, "id": "099f6aa8-a209-483e-be9b-9be1035f5661", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/.hoodie_partition_metadata.parquet#1690859181660573  metageneration=1\n  4.26 MiB  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_868-19-9830_20230731203923454.parquet#1690859181667420  metageneration=1\n   4.3 MiB  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/659d68c7-734c-4604-9e09-339705926683-0_867-19-9829_20230731203923454.parquet#1690859181699337  metageneration=1\nTOTAL: 3 objects, 8974792 bytes (8.56 MiB)\n"}], "source": "# Capture GCS parquet file listing prior to insert\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=2019-03-10\n"}, {"cell_type": "code", "execution_count": 16, "id": "a83b51af-080e-4712-a261-2c47ed908d6b", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Trip count before update: 289823\n"}], "source": "# Capture record count before update\nTRIP_COUNT_BEFORE_UPDATE=spark.sql(f\"select count(*)  from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-01-15'\").collect()[0][0]\nprint(f\"Trip count before update: {TRIP_COUNT_BEFORE_UPDATE}\")\n"}, {"cell_type": "code", "execution_count": 17, "id": "938ddd47-a4df-40c2-ba95-5239e4edf0db", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/.hoodie_partition_metadata.parquet#1690859180071337  metageneration=1\n  4.22 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_478-19-9440_20230731203923454.parquet#1690859180061839  metageneration=1\n  4.22 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/c186a3d2-5697-4367-bd66-0239178a1e4b-0_477-19-9439_20230731203923454.parquet#1690859180086698  metageneration=1\n  1.69 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/ed4c608d-c783-40af-a83e-e4411863865b-0_479-19-9441_20230731203923454.parquet#1690859180101788  metageneration=1\nTOTAL: 4 objects, 10629229 bytes (10.14 MiB)\n"}], "source": "# Capture GCS parquet file listing prior to update\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=2019-01-15\n"}, {"cell_type": "code", "execution_count": 18, "id": "e993a545-1e59-4a53-9c38-7f72a05ed5e1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------+----------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|_hoodie_commit_time|_hoodie_file_name                                                           |trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+-------------------+----------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|20230731203923454  |ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_478-19-9440_20230731203923454.parquet|695784702201|yellow   |1        |2019-01-15 10:00:30|2019-01-15 10:49:46|68                |141                |2019-01-15|\n+-------------------+----------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Capture original record prior to update\nspark.sql(f\"SELECT _hoodie_commit_time,_hoodie_file_name,trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date \" \\\n          f\" FROM taxi_db.nyc_taxi_trips_hudi_cow \"\\\n          f\" WHERE trip_date='2019-01-15' AND trip_id={UPDATE_CANDIDATE_TRIP_ID}\") \\\n        .show(truncate=False)\n"}, {"cell_type": "code", "execution_count": 19, "id": "59437434-3558-41c8-ad51-866ac2324a1b", "metadata": {}, "outputs": [], "source": "# HUDI options for the upsert operation\nhudi_options = {\n            'hoodie.database.name': 'taxi_db',\n            'hoodie.table.name': 'nyc_taxi_trips_hudi_cow',\n            'hoodie.datasource.write.table.name': 'nyc_taxi_trips_hudi_cow',\n            'hoodie.datasource.write.table.type': 'COPY_ON_WRITE',\n            'hoodie.datasource.write.recordkey.field': 'trip_id',\n            'hoodie.datasource.write.partitionpath.field': 'trip_date',\n            'hoodie.datasource.write.precombine.field': 'pickup_datetime',\n            'hoodie.datasource.write.hive_style_partitioning': 'true',\n            'hoodie.partition.metafile.use.base.format': 'true', \n            'hoodie.datasource.write.drop.partition.columns': 'true',\n            'hoodie.datasource.write.operation': 'upsert',\n            'hoodie.datasource.hive_sync.enable': 'true',\n            'hoodie.meta.sync.client.tool.class': 'org.apache.hudi.hive.HiveSyncTool',\n            'hoodie.datasource.hive_sync.mode':'hms',\n            'hoodie.datasource.hive_sync.metastore.uris':DATAPROC_METASTORE_THRIFT_URI,\n            'hoodie.datasource.hive_sync.auto_create_database':'true',\n            'hoodie.datasource.hive_sync.database': 'taxi_db',\n            'hoodie.datasource.hive_sync.table': 'nyc_taxi_trips_hudi_cow',\n            'hoodie.datasource.hive_sync.partition_fields': 'trip_date', \n            'hoodie.datasource.hive_sync.partition_extractor_class':'org.apache.hudi.hive.MultiPartKeysValueExtractor',\n            'hoodie.datasource.hive_sync.use_jdbc': 'false',\n            'hoodie.datasource.hive_sync.support_timestamp': 'true'\n        }\n"}, {"cell_type": "markdown", "id": "e74b7c8a-ef7f-4311-a62d-700bbfe6b0db", "metadata": {}, "source": "### 1.6. Execute the upsert"}, {"cell_type": "code", "execution_count": null, "id": "2372524b-90fc-4e85-9136-de18d1d76b62", "metadata": {}, "outputs": [], "source": "# Append to dataset in GCS, and refresh metadata in Dataproc Metastore for the table\nupsertTripDFCow.write.format(\"hudi\"). \\\n                options(**hudi_options). \\\n                mode(\"append\"). \\\n                save(HUDI_COW_BASE_GCS_URI)\n"}, {"cell_type": "markdown", "id": "8744b5c8-cb24-4d3a-bf4f-ea0705b0336d", "metadata": {}, "source": "### 1.7. Validate the insert"}, {"cell_type": "code", "execution_count": 21, "id": "f42b7c8b-0a1e-4111-93d4-5747fc1813b5", "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "23/08/01 03:28:57 WARN GhfsStorageStatistics: Detected potential high latency for operation stream_read_operations. latencyMs=110; previousMaxLatencyMs=78; operationCount=912; context=gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/20230801032820936.commit\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Trip count before insert was 245530 and trip count after insert is 245531\n"}], "source": "# Record count after insert\nTRIP_COUNT_AFTER_INSERT=spark.sql(f\"select count(*) from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-03-10'\").collect()[0][0]\nprint(f\"Trip count before insert was {TRIP_COUNT_BEFORE_INSERT} and trip count after insert is {TRIP_COUNT_AFTER_INSERT}\")\n"}, {"cell_type": "code", "execution_count": 22, "id": "f79df3fd-3eb0-4849-be8f-1f7f68215fc0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/.hoodie_partition_metadata.parquet#1690859181660573  metageneration=1\n  4.26 MiB  2023-08-01T03:28:40Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_1-49-4155_20230801032820936.parquet#1690860520263515  metageneration=1\n  4.26 MiB  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_868-19-9830_20230731203923454.parquet#1690859181667420  metageneration=1\n   4.3 MiB  2023-08-01T03:06:21Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-03-10/659d68c7-734c-4604-9e09-339705926683-0_867-19-9829_20230731203923454.parquet#1690859181699337  metageneration=1\nTOTAL: 4 objects, 13441377 bytes (12.82 MiB)\n"}], "source": "# GCS parquet file listing after insert - note the extra file\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=$INSERT_TRIP_DATE\n"}, {"cell_type": "code", "execution_count": 23, "id": "23b7f326-8bf1-4ea7-9855-0376346050de", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+--------------------------------------------------------------------------+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|_hoodie_file_name                                                         |trip_id      |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+--------------------------------------------------------------------------+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_1-49-4155_20230801032820936.parquet|1786706865009|yellow   |2        |2019-03-10 14:44:09|2019-03-10 14:59:03|141               |112                |2019-03-10|\n+--------------------------------------------------------------------------+-------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Check for existence of the record and the filename in which it exists\nspark.sql(f\"SELECT _hoodie_file_name,trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date \" \\\n          f\" FROM taxi_db.nyc_taxi_trips_hudi_cow \"\\\n          f\" WHERE trip_date='2019-03-10' AND trip_id={TO_BE_INSERTED_TRIP_ID}\") \\\n        .show(truncate=False)\n"}, {"cell_type": "markdown", "id": "3fbd3470-3a36-4eb0-a3b2-603bb52e5698", "metadata": {}, "source": "### 1.8. Validate the update"}, {"cell_type": "code", "execution_count": 24, "id": "4ca314ee-a631-4ad1-970e-ce3fd6199d86", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Trip count before update was: 289823 and trip count after update is 289823\n"}], "source": "# Record count after update\nTRIP_COUNT_AFTER_UPDATE=spark.sql(f\"select count(*) from taxi_db.nyc_taxi_trips_hudi_cow WHERE trip_date='2019-01-15'\").collect()[0][0]\nprint(f\"Trip count before update was: {TRIP_COUNT_BEFORE_UPDATE} and trip count after update is {TRIP_COUNT_AFTER_UPDATE}\")"}, {"cell_type": "code", "execution_count": 25, "id": "78184877-8c0d-4f2f-96cb-b6709a2c4c36", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "     373 B  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/.hoodie_partition_metadata.parquet#1690859180071337  metageneration=1\n  4.22 MiB  2023-08-01T03:28:40Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_0-49-4154_20230801032820936.parquet#1690860520226622  metageneration=1\n  4.22 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_478-19-9440_20230731203923454.parquet#1690859180061839  metageneration=1\n  4.22 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/c186a3d2-5697-4367-bd66-0239178a1e4b-0_477-19-9439_20230731203923454.parquet#1690859180086698  metageneration=1\n  1.69 MiB  2023-08-01T03:06:20Z  gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/trip_date=2019-01-15/ed4c608d-c783-40af-a83e-e4411863865b-0_479-19-9441_20230731203923454.parquet#1690859180101788  metageneration=1\nTOTAL: 5 objects, 15053741 bytes (14.36 MiB)\n"}], "source": "# GCS parquet file listing after insert\n!gsutil ls -alh $HUDI_COW_BASE_GCS_URI/trip_date=$UPDATE_TRIP_DATE"}, {"cell_type": "code", "execution_count": 26, "id": "6dd99bf7-1260-4e03-9c58-df7a024c1ac1", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+-------------------+--------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|_hoodie_commit_time|_hoodie_file_name                                                         |trip_id     |taxi_type|vendor_id|pickup_datetime    |dropoff_datetime   |pickup_location_id|dropoff_location_id|trip_date |\n+-------------------+--------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n|20230801032820936  |ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_0-49-4154_20230801032820936.parquet|695784702201|yellow   |1        |2019-01-15 11:00:30|2019-01-15 11:49:46|68                |141                |2019-01-15|\n+-------------------+--------------------------------------------------------------------------+------------+---------+---------+-------------------+-------------------+------------------+-------------------+----------+\n\n"}], "source": "# Check for update\nspark.sql(f\"SELECT _hoodie_commit_time,_hoodie_file_name,trip_id,taxi_type,vendor_id,pickup_datetime,dropoff_datetime,pickup_location_id,dropoff_location_id,trip_date\" \\\n          f\" FROM taxi_db.nyc_taxi_trips_hudi_cow \"\\\n          f\" WHERE trip_date='2019-01-15' AND trip_id={UPDATE_CANDIDATE_TRIP_ID}\") \\\n        .show(truncate=False)"}, {"cell_type": "markdown", "id": "e788f17b-e510-4eb2-9070-77fd66ce1ec9", "metadata": {}, "source": "### 1.9. Study the commit log"}, {"cell_type": "code", "execution_count": 27, "id": "c5a9cc47-e281-4917-9095-bfbac47b98f0", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Log file FQP is gs://gaia_data_bucket-623600433888/nyc-taxi-trips-hudi-cow/.hoodie/20230801032820936.commit\n"}], "source": "LOG_FILE_LIST=!gsutil ls $HUDI_COW_BASE_GCS_URI/.hoodie/*.commit | tail -n 1 \nLOG_FILE=LOG_FILE_LIST[0]\nprint(f\"Log file FQP is {LOG_FILE}\")"}, {"cell_type": "markdown", "id": "2b631972-0bb3-43a7-beb0-5d815f5f70d9", "metadata": {}, "source": "Notice the insert and the update in the latest commit log"}, {"cell_type": "code", "execution_count": 28, "id": "903927f1-fdac-4283-876b-73738669d609", "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "{\n  \"partitionToWriteStats\" : {\n    \"trip_date=2019-01-15\" : [ {\n      \"fileId\" : \"ab386b38-4ae1-4e57-b044-46bd2f79c14e-0\",\n      \"path\" : \"trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_0-49-4154_20230801032820936.parquet\",\n      \"prevCommit\" : \"20230731203923454\",\n      \"numWrites\" : 122745,\n      \"numDeletes\" : 0,\n      \"numUpdateWrites\" : 1,\n      \"numInserts\" : 0,\n      \"totalWriteBytes\" : 4424512,\n      \"totalWriteErrors\" : 0,\n      \"tempPath\" : null,\n      \"partitionPath\" : \"trip_date=2019-01-15\",\n      \"totalLogRecords\" : 0,\n      \"totalLogFilesCompacted\" : 0,\n      \"totalLogSizeCompacted\" : 0,\n      \"totalUpdatedRecordsCompacted\" : 0,\n      \"totalLogBlocks\" : 0,\n      \"totalCorruptLogBlock\" : 0,\n      \"totalRollbackBlocks\" : 0,\n      \"fileSizeInBytes\" : 4424512,\n      \"minEventTime\" : null,\n      \"maxEventTime\" : null\n    } ],\n    \"trip_date=2019-03-10\" : [ {\n      \"fileId\" : \"340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0\",\n      \"path\" : \"trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_1-49-4155_20230801032820936.parquet\",\n      \"prevCommit\" : \"20230731203923454\",\n      \"numWrites\" : 122147,\n      \"numDeletes\" : 0,\n      \"numUpdateWrites\" : 0,\n      \"numInserts\" : 1,\n      \"totalWriteBytes\" : 4466585,\n      \"totalWriteErrors\" : 0,\n      \"tempPath\" : null,\n      \"partitionPath\" : \"trip_date=2019-03-10\",\n      \"totalLogRecords\" : 0,\n      \"totalLogFilesCompacted\" : 0,\n      \"totalLogSizeCompacted\" : 0,\n      \"totalUpdatedRecordsCompacted\" : 0,\n      \"totalLogBlocks\" : 0,\n      \"totalCorruptLogBlock\" : 0,\n      \"totalRollbackBlocks\" : 0,\n      \"fileSizeInBytes\" : 4466585,\n      \"minEventTime\" : null,\n      \"maxEventTime\" : null\n    } ]\n  },\n  \"compacted\" : false,\n  \"extraMetadata\" : {\n    \"schema\" : \"{\\\"type\\\":\\\"record\\\",\\\"name\\\":\\\"nyc_taxi_trips_hudi_cow_record\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow\\\",\\\"fields\\\":[{\\\"name\\\":\\\"taxi_type\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_year\\\",\\\"type\\\":[\\\"null\\\",\\\"int\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_month\\\",\\\"type\\\":[\\\"null\\\",\\\"int\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_day\\\",\\\"type\\\":[\\\"null\\\",\\\"int\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_hour\\\",\\\"type\\\":[\\\"null\\\",\\\"int\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_minute\\\",\\\"type\\\":[\\\"null\\\",\\\"int\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"vendor_id\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"pickup_datetime\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-micros\\\"}],\\\"default\\\":null},{\\\"name\\\":\\\"dropoff_datetime\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"long\\\",\\\"logicalType\\\":\\\"timestamp-micros\\\"}],\\\"default\\\":null},{\\\"name\\\":\\\"store_and_forward\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"rate_code\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"pickup_location_id\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"dropoff_location_id\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"passenger_count\\\",\\\"type\\\":[\\\"null\\\",\\\"long\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_distance\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.trip_distance\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"fare_amount\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.fare_amount\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"surcharge\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.surcharge\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"mta_tax\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.mta_tax\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"tip_amount\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.tip_amount\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"tolls_amount\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.tolls_amount\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"improvement_surcharge\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.improvement_surcharge\\\",\\\"size\\\":5,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":10,\\\"scale\\\":0}],\\\"default\\\":null},{\\\"name\\\":\\\"total_amount\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.total_amount\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"payment_type_code\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"congestion_surcharge\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.congestion_surcharge\\\",\\\"size\\\":5,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":10,\\\"scale\\\":0}],\\\"default\\\":null},{\\\"name\\\":\\\"trip_type\\\",\\\"type\\\":[\\\"null\\\",\\\"string\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"ehail_fee\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.ehail_fee\\\",\\\"size\\\":5,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":10,\\\"scale\\\":0}],\\\"default\\\":null},{\\\"name\\\":\\\"partition_date\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"int\\\",\\\"logicalType\\\":\\\"date\\\"}],\\\"default\\\":null},{\\\"name\\\":\\\"distance_between_service\\\",\\\"type\\\":[\\\"null\\\",{\\\"type\\\":\\\"fixed\\\",\\\"name\\\":\\\"fixed\\\",\\\"namespace\\\":\\\"hoodie.nyc_taxi_trips_hudi_cow.nyc_taxi_trips_hudi_cow_record.distance_between_service\\\",\\\"size\\\":16,\\\"logicalType\\\":\\\"decimal\\\",\\\"precision\\\":38,\\\"scale\\\":9}],\\\"default\\\":null},{\\\"name\\\":\\\"time_between_service\\\",\\\"type\\\":[\\\"null\\\",\\\"long\\\"],\\\"default\\\":null},{\\\"name\\\":\\\"trip_id\\\",\\\"type\\\":[\\\"null\\\",\\\"long\\\"],\\\"default\\\":null}]}\"\n  },\n  \"operationType\" : \"UPSERT\",\n  \"totalRecordsDeleted\" : 0,\n  \"totalLogRecordsCompacted\" : 0,\n  \"totalLogFilesCompacted\" : 0,\n  \"totalCompactedRecordsUpdated\" : 0,\n  \"totalLogFilesSize\" : 0,\n  \"totalScanTime\" : 0,\n  \"totalCreateTime\" : 0,\n  \"totalUpsertTime\" : 9970,\n  \"minAndMaxEventTime\" : {\n    \"Optional.empty\" : {\n      \"val\" : null,\n      \"present\" : false\n    }\n  },\n  \"writePartitionPaths\" : [ \"trip_date=2019-01-15\", \"trip_date=2019-03-10\" ],\n  \"fileIdAndRelativePaths\" : {\n    \"ab386b38-4ae1-4e57-b044-46bd2f79c14e-0\" : \"trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_0-49-4154_20230801032820936.parquet\",\n    \"340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0\" : \"trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_1-49-4155_20230801032820936.parquet\"\n  },\n  \"writeStats\" : [ {\n    \"fileId\" : \"ab386b38-4ae1-4e57-b044-46bd2f79c14e-0\",\n    \"path\" : \"trip_date=2019-01-15/ab386b38-4ae1-4e57-b044-46bd2f79c14e-0_0-49-4154_20230801032820936.parquet\",\n    \"prevCommit\" : \"20230731203923454\",\n    \"numWrites\" : 122745,\n    \"numDeletes\" : 0,\n    \"numUpdateWrites\" : 1,\n    \"numInserts\" : 0,\n    \"totalWriteBytes\" : 4424512,\n    \"totalWriteErrors\" : 0,\n    \"tempPath\" : null,\n    \"partitionPath\" : \"trip_date=2019-01-15\",\n    \"totalLogRecords\" : 0,\n    \"totalLogFilesCompacted\" : 0,\n    \"totalLogSizeCompacted\" : 0,\n    \"totalUpdatedRecordsCompacted\" : 0,\n    \"totalLogBlocks\" : 0,\n    \"totalCorruptLogBlock\" : 0,\n    \"totalRollbackBlocks\" : 0,\n    \"fileSizeInBytes\" : 4424512,\n    \"minEventTime\" : null,\n    \"maxEventTime\" : null\n  }, {\n    \"fileId\" : \"340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0\",\n    \"path\" : \"trip_date=2019-03-10/340b03dc-b6e3-4113-b93a-c1d0e4f330e7-0_1-49-4155_20230801032820936.parquet\",\n    \"prevCommit\" : \"20230731203923454\",\n    \"numWrites\" : 122147,\n    \"numDeletes\" : 0,\n    \"numUpdateWrites\" : 0,\n    \"numInserts\" : 1,\n    \"totalWriteBytes\" : 4466585,\n    \"totalWriteErrors\" : 0,\n    \"tempPath\" : null,\n    \"partitionPath\" : \"trip_date=2019-03-10\",\n    \"totalLogRecords\" : 0,\n    \"totalLogFilesCompacted\" : 0,\n    \"totalLogSizeCompacted\" : 0,\n    \"totalUpdatedRecordsCompacted\" : 0,\n    \"totalLogBlocks\" : 0,\n    \"totalCorruptLogBlock\" : 0,\n    \"totalRollbackBlocks\" : 0,\n    \"fileSizeInBytes\" : 4466585,\n    \"minEventTime\" : null,\n    \"maxEventTime\" : null\n  } ]\n}"}], "source": "!gsutil cat $LOG_FILE"}, {"cell_type": "markdown", "id": "0209097d-a2c5-4bc1-8707-0457ad2f31c9", "metadata": {}, "source": "This concludes the unit. Please proceed to the next notebook."}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}, "toc-showcode": true}, "nbformat": 4, "nbformat_minor": 5}